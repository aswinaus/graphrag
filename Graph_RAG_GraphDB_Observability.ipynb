{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNCXP08gv45kUjKzxRL+ajm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinaus/graphrag/blob/main/Graph_RAG_GraphDB_Observability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVDhdnIvu8O8"
      },
      "outputs": [],
      "source": [
        "%pip install pyvis IPython cchardet datasets langchain==0.1.17 neo4j openai tiktoken langchain-community langchain-experimental json-repair\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "CZuwREx40lwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.2\n",
        "!pip install pandas==2.0.3\n",
        "!pip install datasets==2.14.5"
      ],
      "metadata": {
        "id": "8poJUJD8-lzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "dataset = load_dataset(\"aswinaus/tax_statistics_dataset_by_income_range\", download_mode=\"force_redownload\")\n",
        "df=pd.DataFrame(dataset['train'])"
      ],
      "metadata": {
        "id": "8uhqUOej01Jc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "SXWJwp2WfHIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code imagine each state as a circle (a node) and you want to connect it to another circle representing the number of tax returns filed in that state. This line of code draws that connection (an edge) between the 'STATE' node and the 'No of returns' node. It also labels the connection with 'Size of adjusted gross income' to indicate the relationship between them.\n",
        "\n",
        "Scenario:If the current row in the dataset has 'STATE' as 'CA' and 'No of returns' as 1000, this line would create an edge in the graph connecting a node labeled 'CA' to a node labeled '1000', and the edge would be labeled with 'Size of adjusted gross income'.\n",
        "\n",
        "Nodes: In a graph, nodes (sometimes called vertices) are the fundamental entities. In this code, nodes represent things like U.S. states, or categories like \"Number of Returns\" or \"Size of adjusted gross income.\"\n",
        "\n",
        "Edges: Edges are the connections between nodes. They represent relationships. In this code, an edge connects a state node to a tax return statistic node, and the edge is labeled with a \"Size of adjusted gross income\" attribute.\n"
      ],
      "metadata": {
        "id": "WqAwygvyP3TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Knowledge Graph Builder & Visualizer {\"display-mode\":\"code\"}\n",
        "# @markdown Note that rendering the graph will take a minute or two under the default 10% sample size, longer with higher sample sizes.\n",
        "sample_size = 0.66 # @param {type:\"number\", default:0.10}\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from pyvis.network import Network\n",
        "from IPython.display import IFrame\n",
        "from IPython.display import Markdown, HTML\n",
        "\n",
        "colors = {\n",
        "    'STATE': 'Darkblue',\n",
        "    'Number of electronically filed returns': 'orange',\n",
        "    'No of returns': 'red',\n",
        "    'No of single returns': 'green',\n",
        "    'No of joint returns': 'magenta',\n",
        "    'No of head of household returns': 'purple',\n",
        "}\n",
        "sizes = {\n",
        "    'STATE': 20,\n",
        "    'Number of electronically filed returns': 25,\n",
        "    'No of returns': 25,\n",
        "    'No of single returns': 25,\n",
        "    'No of joint returns': 25,\n",
        "    'No of head of household returns': 25\n",
        "}\n",
        "\n",
        "#Stratification is a sampling technique where you divide your data into subgroups (called strata) based on certain characteristics. This ensures that your sample has a similar distribution of these characteristics as the original dataset, making it more representative.\n",
        "#code is indicating that the dataset will be divided into strata based on the values in the Size of adjusted gross income and 'STATE' columns.\n",
        "stratify_cols = ['Size of adjusted gross income', 'STATE']\n",
        "#This line sets the sample_size variable to 0.6, meaning that 60% of the data from each stratum will be sampled.\n",
        "sample_size = 0.6\n",
        "\n",
        "# This part uses the groupby() method to group the DataFrame df based on the columns specified in stratify_cols. The group_keys=False argument prevents the group keys from being added as index levels in the result.\n",
        "# Second part applies a function to each group created by groupby(). The function used here is a lambda function that calls the sample() method on each group with frac=sample_size. This means it takes a random sample of the specified fraction (60% in this case) from each group.\n",
        "sampled_df = df.groupby(stratify_cols, group_keys=False).apply(lambda x: x.sample(frac=sample_size))\n",
        "\n",
        "# Initialize a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Adding nodes with the entity type as a node attribute\n",
        "#This line initiates a loop that iterates through each row of the sampled_df DataFrame.\n",
        "#index: Represents the index of the current row.\n",
        "#row: Represents the data within the current row, accessible like a dictionary (e.g., row['STATE'] gets the value in the 'STATE' column).\n",
        "for index, row in sampled_df.iterrows():\n",
        "    incometaxby_state_name=f\"{row['STATE']}_{row['zipcode']}_{row['Size of adjusted gross income']}\"\n",
        "    #This condition checks if a node representing the current state (row['STATE']) already exists in the graph G. It proceeds only if the node doesn't exist.\n",
        "    if row['STATE'] not in G:\n",
        "      #This is the value used to identify the node, likely the state's name (e.g., 'CA', 'NY')\n",
        "      G.add_node(row['STATE'],\n",
        "                 #entity='STATE': This assigns an attribute named entity with the value 'STATE' to the node, categorizing it as a state node.\n",
        "                 entity='STATE',\n",
        "                 #color=colors.get('STATE', 'blue'): This sets the color of the node. It uses the colors dictionary to find a color associated with 'STATE'. If not found, it defaults to 'blue'.\n",
        "                 color=colors.get('STATE', 'blue'),\n",
        "                 #size=sizes.get('STATE', 5): Similar to color, this sets the size of the node based on the sizes dictionary, defaulting to 5 if not specified.\n",
        "                 size=sizes.get('STATE', 5), )\n",
        "#The above code goes through the dataset, and for each state it encounters that's not already in the graph, it creates a new node representing that state. The node is given attributes to define its type, color, and size within the visualization.\n",
        "\n",
        "    if row['Size of adjusted gross income'] not in G:\n",
        "      G.add_node(row['Size of adjusted gross income'],\n",
        "                 entity='Size_of_adjusted_gross_income',\n",
        "                 color=colors.get('Size of adjusted gross income', 'gray'),\n",
        "                 size=sizes.get('Size of adjusted gross income', 40))\n",
        "\n",
        "    #G.add_node(\n",
        "    #           row['zipcode'],\n",
        "    #           entity='ZIPCODE',\n",
        "    #           color=colors.get('ZIPCODE', 'orange'),\n",
        "    #           size=sizes.get('ZIPCODE', 20))\n",
        "    if row['No of returns'] not in G:\n",
        "      G.add_node(\n",
        "               row['No of returns'],\n",
        "               entity='No_of_returns',\n",
        "               color=colors.get('No_of_returns', 'green'),\n",
        "               size=sizes.get('No_of_returns', 25))\n",
        "\n",
        "    if row['No of single returns'] not in G:\n",
        "      G.add_node(\n",
        "               row['No of single returns'],\n",
        "               entity='No_of_single_returns',\n",
        "               color=colors.get('No_of_single_returns', 'orange'),\n",
        "               size=sizes.get('No_of_returns', 25))\n",
        "\n",
        "    if row['No of joint returns'] not in G:\n",
        "      G.add_node(\n",
        "               row['No of joint returns'],\n",
        "               entity='No_of_joint_returns',\n",
        "               color=colors.get('No_of_joint_returns', 'magenta'),\n",
        "               size=sizes.get('No_of_joint_returns',25))\n",
        "\n",
        "      if row['No of head of household returns'] not in G:\n",
        "        G.add_node(\n",
        "               row['No of head of household returns'],\n",
        "               entity='No_of_head_of_household_returns',\n",
        "               color=colors.get('No_of_head_of_household_returns', 'purple'),\n",
        "               size=sizes.get('No_of_head_of_household_returns',25))\n",
        "\n",
        "        if row['Number of electronically filed returns'] not in G:\n",
        "          G.add_node(\n",
        "               row['Number of electronically filed returns'],\n",
        "               entity='Number_of_electronically_filed_returns',\n",
        "               color=colors.get('Number_of_electronically_filed_returns', 'Yellow'),\n",
        "               size=sizes.get('Number_of_electronically_filed_returns',25))\n",
        "\n",
        "    #using the networkx library in Python to add an edge (a connection) to a graph (G).\n",
        "    #G is the graph object, add_edge is function in networkx adds a new edge(connection) to the graph G\n",
        "    #row['STATE'] Refers to the value in the STATE column to the current row(row) ibeing processed from the dataset representing source node of the edge.\n",
        "    #row['No of returns']: This refers to the value in the 'No of returns' column of the current row. It represents the target node of the edge.\n",
        "    #relationship='Size of adjusted gross income': This assigns an attribute named relationship to the edge, and sets its value to 'Size of adjusted gross income'. This provides information about the type or nature of the connection between the two nodes.\n",
        "    G.add_edge(row['STATE'], row['No of returns'],relationship='Size of adjusted gross income')\n",
        "    G.add_edge(row['STATE'], row['No of single returns'],relationship='Size of adjusted gross income')\n",
        "    G.add_edge(row['STATE'], row['No of joint returns'],relationship='Size of adjusted gross income')\n",
        "\n",
        "    G.add_edge(row['STATE'], row['No of head of household returns'],relationship='Size of adjusted gross income')\n",
        "    G.add_edge(row['STATE'], row['Number of electronically filed returns'],relationship='Size of adjusted gross income')\n",
        "\n",
        "\n",
        "# Step 4: Visualization\n",
        "# Convert to a pyvis network\n",
        "nt = Network('1000px', '1000px', notebook=True, cdn_resources='in_line')\n",
        "# if you are not in a Jupyter environment, you might need to set notebook=False\n",
        "nt.from_nx(G)\n",
        "nt.toggle_physics(True)  # Enable force-directed algorithm\n",
        "nt.save_graph('income_tax_2019_graph.html')\n",
        "nt.show('income_tax_2019_graph.html')\n",
        "\n",
        "HTML('income_tax_2019_graph.html')"
      ],
      "metadata": {
        "id": "OwWhZp0nkldh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre ipywidgets"
      ],
      "metadata": {
        "id": "VFl2Ah0NeH0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "from google.colab import userdata\n",
        "\n",
        "url = userdata.get('NEO4J_URI')\n",
        "username =\"neo4j\"\n",
        "password = userdata.get('NEO4J_PASSWORD')\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get('OPENAI_API_KEY')\n",
        "driver = GraphDatabase.driver(url, auth=(username, password))"
      ],
      "metadata": {
        "id": "7SQmUjYh9sDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_type(node):\n",
        "    if isinstance(node, int):\n",
        "        return \"Number\"  # Example: All integer nodes are 'Number' entity\n",
        "    elif node.startswith(\"STATE_\"):\n",
        "        return \"State\"   # Example: Nodes starting with 'STATE_' are 'State' entity\n",
        "    elif node.lower() in [\"true\", \"false\"]:\n",
        "        return \"Boolean\"  # Example: Nodes with values 'true' or 'false' are 'Boolean'\n",
        "    else:\n",
        "        return \"Unknown\"   # Default entity type for unmatched nodes"
      ],
      "metadata": {
        "id": "vRkh1RMiyw7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DG.add_nodes_from(node_names)\n",
        "#DG.add_edges_from(edges)\n",
        "#G is a variable that represents the graph object that was created earlier in the code using nx.DiGraph()\n",
        "\n",
        "total_nodes = G.number_of_nodes()\n",
        "total_edges = G.number_of_edges()\n",
        "total_attributes = sum(len(G.nodes[node]) for node in G.nodes)\n",
        "\n",
        "entity_attributes = nx.get_node_attributes(G, 'entity')\n",
        "\n",
        "print(entity_attributes)\n",
        "print(total_nodes)\n",
        "print(total_edges)\n",
        "print(total_attributes)\n",
        "#For all the nodes if there is no entity attribute fill with an appropriate entity type\n",
        "for node in G.nodes():\n",
        "        if 'entity' not in G.nodes[node]:\n",
        "          print(G.nodes[node])\n",
        "          # Determine the entity type based on your logic or data source\n",
        "          entity_type = get_entity_type(node)\n",
        "          G.nodes[node]['entity'] = entity_type"
      ],
      "metadata": {
        "id": "k3Ibmlo1oxCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Following code takes a graph structure created in Python and efficiently stores it within a Neo4j database, using Cypher queries to create nodes and relationships and set their properties.**"
      ],
      "metadata": {
        "id": "DTbN836TPOt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_graph_to_neo4j(driver, graph):\n",
        "    #driver: This is an object that represents the connection to the Neo4j database.\n",
        "    #establishes a session with the Neo4j database. A session is like a temporary workspace where you can execute queries. The with statement ensures that the session is properly closed after use.\n",
        "    with driver.session() as session:\n",
        "        #Adding Nodes\n",
        "        #graph: This is the graph object (G in the previous code) that you want to store in Neo4j.\n",
        "        #MERGE (n:__Entity__ {name: $name, entity: $entity}) : Find a node with the given name and entity. If it doesn't exist, it creates one.\n",
        "        #SET n += $props : Set properties on the node based on the node's attributes.\n",
        "        #WITH n CALL apoc.create.addLabels(n, ['{label}']) YIELD node : Adds a specific label to the node using the APOC library function.\n",
        "        #RETURN distinct 'done' AS result: Simply return 'done' to indicate success.\n",
        "        #session.run() execute the Cypher query against the database.\n",
        "        for node, attrs in graph.nodes(data=True):\n",
        "            cypher_query = \"\"\"\n",
        "            MERGE (n:__Entity__ {{name: $name,entity:$entity}})\n",
        "            SET n += $props\n",
        "            WITH n\n",
        "            CALL apoc.create.addLabels( n, ['{label}'] ) YIELD node\n",
        "            RETURN distinct 'done' AS result\n",
        "            \"\"\".format(label=attrs['entity'])  # Dynamically set the label based on the 'entity' attribute\n",
        "            session.run(cypher_query, name=node, entity=attrs['entity'], props={k: v for k, v in attrs.items() if k not in ['entity']})\n",
        "\n",
        "\n",
        "        #Adding Edges (Relationships)\n",
        "        #Iterates through the edges (relationships) in the graph object.\n",
        "        #graph.edges(data=True) gives the source node, target node, and edge attributes for each edge.\n",
        "        #It constructs another Cypher query:\n",
        "        #MATCH (a),(b) WHERE a.name = $source AND b.name = $target: This finds the source and target nodes by their names.\n",
        "        #MERGE (a)-[r:{relationship}]->(b): This creates or updates the relationship between the nodes with the specified type.\n",
        "        #SET r += $props: This sets properties on the relationship.\n",
        "        #session.run() executes the query.\n",
        "        for source, target, attrs in graph.edges(data=True):\n",
        "            # Replace spaces in relationship type with underscores\n",
        "            relationship_type = attrs['relationship'].replace(' ', '_')\n",
        "            cypher_query = \"\"\"\n",
        "            MATCH (a),(b)\n",
        "            WHERE a.name =$source and b.name=$target\n",
        "            MERGE (a)-[r:{relationship}]->(b)\n",
        "            SET r += $props\n",
        "            \"\"\".format(relationship=relationship_type)  # Dynamically set the relationship type\n",
        "            session.run(cypher_query, source=source, target=target, props={k: v for k, v in attrs.items() if k not in ['relationship']})\n",
        "\n",
        "# Finally, call the function to add your graph to Neo4j\n",
        "add_graph_to_neo4j(driver, G)"
      ],
      "metadata": {
        "id": "10u2ynTo-iG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "text_node_properties=['name', 'entity', 'zipcode'],\n",
        "Imagine we have nodes in Neo4j database representing tax information. Each node might have properties like:\n",
        "\n",
        "name: The name of a state (e.g., 'California').\n",
        "entity: The type of entity the node represents (e.g., 'State', 'Tax Return').\n",
        "zipcode: The zipcode associated with the data.\n",
        "When the Neo4jVector is created with text_node_properties=['name', 'entity', 'zipcode'], code will:\n",
        "\n",
        "Look at each node in the database.\n",
        "Retrieve the values from the 'name', 'entity', and 'zipcode' properties of that node.\n",
        "Combine those values into a single text string.\n",
        "Use that text string to create an embedding (a numerical representation of the text) using OpenAI's embeddings.\n",
        "\n",
        "These embeddings are then used for similarity searches. When you perform a search, your query is also converted into an embedding, and the Neo4jVector finds the nodes in the database with the most similar embeddings, meaning they are semantically related to your query."
      ],
      "metadata": {
        "id": "NIAg7ka6Z36N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "#Initialize a Neo4jVector object and assigns it to the variable vector_index. It leverages the from_existing_graph method, indicating that it's working with an already populated Neo4j graph\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    #This part specifies that the index will utilize OpenAI's embeddings.\n",
        "    OpenAIEmbeddings(),\n",
        "    #These parameters provide the connection details for the Neo4j database. url points to the database's address, while username and password are used for authentication.\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    #This sets the name of the vector index to 'incometax'. This name will be used to refer to the index within Neo4j.\n",
        "    index_name='incometax',\n",
        "    #This indicates that the vector index should be built on nodes with the label \"__Entity__\" in the graph. In Neo4j, labels categorize nodes with similar characteristics.\n",
        "    node_label=\"__Entity__\",\n",
        "    #Use the values stored in the 'name', 'entity', and 'zipcode' properties of each node to generate embeddings.\"\n",
        "    text_node_properties=['name', 'entity', 'zipcode'],\n",
        "    embedding_node_property='embedding',\n",
        ")"
      ],
      "metadata": {
        "id": "OjkpMHKF5AU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = vector_index.similarity_search(\n",
        "    \"Does state AL have any tax returns ?\"\n",
        ")"
      ],
      "metadata": {
        "id": "Fl9haunB5gRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0].page_content)"
      ],
      "metadata": {
        "id": "RoNNU0dT52Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "vector_qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(),\n",
        "    #This chooses the \"stuff\" chain type, which means the retrieved documents will be inserted directly into the prompt for the LLM.\n",
        "    chain_type=\"stuff\",\n",
        "    #connect the chain to the vector_index (created in the previous part of code) which is used to retrieve relevant information from Neo4j database. .as_retriever() turns the vector_index into a retriever object that the RetrievalQA chain can use.\n",
        "    retriever=vector_index.as_retriever()\n",
        ")\n",
        "vector_qa.run(\n",
        "    \"Compare No of returns,\tNo of single returns,\tNo of joint returns and\tNo of head of household returns for States CA and AL in all the income range?\"\n",
        ")"
      ],
      "metadata": {
        "id": "qBp4k3DmdSP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines two prompt templates using LangChain's PromptTemplate class: CYPHER_GENERATION_PROMPT and CYPHER_QA_PROMPT. These templates are essentially blueprints for creating prompts that will be fed to a large language model (LLM).\n",
        "In essence, these prompt templates ensure that the LLMs are properly guided to generate Cypher queries and provide meaningful answers based on the data retrieved from the Neo4j database."
      ],
      "metadata": {
        "id": "Fg9udvtQwYW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "#This template provides clear instructions to the LLM, emphasizing that it should only use the schema provided and strictly focus on generating a Cypher query.\n",
        "#Placeholders below\n",
        "#{schema}: This will be replaced with the actual schema of the database.\n",
        "#{question}: This will be replaced with the user's question.\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema. However, always exclude the schema's `embedding` property from the Cypher statement.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "\n",
        "The question is:\n",
        "{question}\n",
        "\n",
        "Cypher Query:\n",
        "\"\"\"\n",
        "\n",
        "#This template guides the LLM to format the answer nicely and instructs it to rely solely on the provided context (results from the Cypher query) without using its own knowledge.\n",
        "#It includes placeholders: {context}: This will be replaced with the data retrieved from the database.\n",
        "#{question}: This will be replaced with the original user question.\n",
        "CYPHER_QA_TEMPLATE = \"\"\"You are an AI assistant that helps to form nice and human understandable answers.\n",
        "The information part contains the provided information that you must use to construct an answer.\n",
        "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
        "Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
        "Here is an example:\n",
        "\n",
        "Question: Which state has the maximum number of returns?\n",
        "Context:[{{'STATE': 'CA'}}, {{'No_of_return': '5506120'}}]\n",
        "Helpful Answer: The state CA has the maximum number of returns with 5506120\n",
        "\n",
        "Follow this example when generating answers.\n",
        "If the provided information is empty, say that you don't know the answer.\n",
        "\n",
        "Information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "#This prompt is designed to instruct the LLM to generate a Cypher query (Neo4j's query language) based on a user's question and a provided schema of the graph database.\n",
        "#create the CYPHER_GENERATION_PROMPT object using the PromptTemplate class.\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    #Use the CYPHER_GENERATION_TEMPLATE as the base structure.\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "#This prompt is used to instruct the LLM to generate a human-readable answer based on the results returned from the Cypher query.\n",
        "CYPHER_QA_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], template=CYPHER_QA_TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "yey_lamFd68q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import TransformChain\n",
        "\n",
        "def transform_cypher(input):\n",
        "  # Replace spaces in labels with backticks:\n",
        "  modified_cypher = input['cypher_statement'].replace(\"MATCH (n:Size of adjusted gross income)\", \"MATCH (n:`Size of adjusted gross income`)\")\n",
        "  # Add more replacements for other labels/properties with spaces as needed.\n",
        "  return {'modified_cypher': modified_cypher}"
      ],
      "metadata": {
        "id": "vT8Zrnf7hRXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Set the OpenAI API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] =  userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGSMITH_PROJECT\"]=\"agent_observability\"\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get('OPENAI_API_KEY')\n",
        "LANGSMITH_TRACING=True\n",
        "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
        "LANGSMITH_API_KEY=userdata.get('LANGCHAIN_API_KEY')\n",
        "LANGSMITH_PROJECT=\"agent_observability\"\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "FzSk5nBmeSxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code sets up a question-answering system that uses a Neo4j graph database. It defines a connection to the database, refreshes the schema, and creates a chain using OpenAI's LLMs to translate user questions into Cypher queries, execute those queries against the database, and then format the results into human-readable answers. The CYPHER_QA_PROMPT and CYPHER_GENERATION_PROMPT above play a crucial role in guiding the LLMs to perform these tasks accurately."
      ],
      "metadata": {
        "id": "SReDvPr4gZ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    enhanced_schema=True\n",
        ")\n",
        "#refresh the schema to latest\n",
        "graph.refresh_schema()\n",
        "\n",
        "#transform_chain = TransformChain(input_variables=[\"cypher_statement\"], output_variables=[\"modified_cypher\"], transform_function=transform_cypher)\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    cypher_llm = ChatOpenAI(temperature=0, model_name='gpt-4'),\n",
        "    qa_llm = ChatOpenAI(temperature=0),\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    qa_prompt=CYPHER_QA_PROMPT,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT\n",
        ")\n",
        "\n",
        "#cypher_chain.llm_chain.prompt.template = \"{cypher_statement}\"\n",
        "#cypher_chain = transform_chain | cypher_chain"
      ],
      "metadata": {
        "id": "Q8Izn-sCfq8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_chain.run(\n",
        "    \"Can you compare No of returns,\tNo of single returns,\tNo of joint returns and\tNo of head of household returns for States GA and CA in all the income range?\"\n",
        ")"
      ],
      "metadata": {
        "id": "Wz3k2JMfoYM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code creates an AI agent that can answer tax-related questions by using either a similarity search (VectorSearch) or a graph database query (GraphSearch). The agent uses GPT-4 to figure out the best tool for each question.\n",
        "\n",
        "Code defines two tools which the TaxAgent will have access to:\n",
        "\n",
        "VectorSearch: This tool uses a technique called similarity search to find relevant information. It's good for general questions about tax statistics. It likely uses the vector_qa object (defined earlier in the code, but not shown here) to perform the search.\n",
        "\n",
        "GraphSearch: This tool uses a graph database (Neo4j) to find more specific, analytical information. It likely uses the cypher_chain object (also defined earlier) to query the database.\n",
        "Each tool has a name, a func (the function it calls to do its work), and a description that tells the agent what it's good for."
      ],
      "metadata": {
        "id": "KNv64AvkB95S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"VectorSearch\",\n",
        "        func=vector_qa.run,\n",
        "        description=\"\"\"Answer questions related to tax statistics.\n",
        "        For non analytic questions, use the VectorSearch tool.\n",
        "        Always have complete questions as input.\n",
        "        \"\"\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"GraphSearch\",\n",
        "        func=cypher_chain.run,\n",
        "        description=\"\"\"Useful for questions related to tax mostly analytical data querying,\n",
        "        Always have complete questions as input.\n",
        "        \"\"\",\n",
        "    ),\n",
        "]\n",
        "#Agent Initialization\n",
        "#initialize_agent: This function from LangChain is used to create the agent.\n",
        "#tools: The list of tools (VectorSearch and GraphSearch) is passed to the agent, giving it access to these functionalities.\n",
        "#ChatOpenAI(temperature=0, model_name='gpt-4'): This specifies that the agent will use OpenAI's GPT-4 language model as its reasoning engine. temperature=0 makes the model's responses more deterministic.\n",
        "#agent=AgentType.OPENAI_FUNCTIONS: This selects a specific agent type from LangChain designed for interacting with tools using OpenAI's function calling capabilities.\n",
        "#verbose=True: This setting enables detailed logging of the agent's actions, which is helpful for debugging and understanding how it's making decisions.\n",
        "TaxAgent = initialize_agent(\n",
        "    tools,\n",
        "    ChatOpenAI(temperature=0, model_name='gpt-4'),\n",
        "    agent=AgentType.OPENAI_FUNCTIONS, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "JY-BlE6SAItF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = TaxAgent.invoke({\"input\": \"How many states have a No of returns greater than 10000\"})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "cUz2eOUWDFjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n",
        "!pip install fastapi nest-asyncio --quiet\n",
        "!pip install uvicorn --quiet"
      ],
      "metadata": {
        "id": "4TsHu4tl-_AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "zubXvF-3_Ydj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Request, BackgroundTasks\n",
        "from fastapi.responses import StreamingResponse\n",
        "from threading import Thread\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Variables for time measurements\n",
        "start_time = 0\n",
        "first_token_time = 0\n",
        "token_times = []\n",
        "\n",
        "# Invoke the LLM chain using the input text\n",
        "def invoke_tax_agent(input_text):\n",
        "    response=TaxAgent.invoke(input_text)\n",
        "    return response\n",
        "\n",
        "# Generate output text using the streamer\n",
        "def generate_output(streamer):\n",
        "    global start_time, first_token_time, token_times, model_output\n",
        "    model_output = \"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, new_text in enumerate(streamer):\n",
        "        model_output += new_text\n",
        "\n",
        "        # Measure time for the first token\n",
        "        if i == 0:\n",
        "            first_token_time = time.time()\n",
        "\n",
        "        # Measure time for each token\n",
        "        token_times.append(time.time())\n",
        "        yield new_text\n",
        "\n",
        "    metrics = start_time, first_token_time, token_times, model_output\n",
        "    print(\"Metrics:\", metrics)\n",
        "    return metrics\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Hello, World!\"}\n",
        "\n",
        "@app.post(\"/graphDB-inference\")\n",
        "async def graphDB_inference(input_text: dict, background_tasks: BackgroundTasks):\n",
        "    # Start a separate thread to run the tax agent asynchronously\n",
        "    thread = Thread(target=invoke_tax_agent, args=[input_text])\n",
        "    thread.start()\n",
        "\n",
        "    # Add the generate_output function to the background tasks with the streamer\n",
        "    #background_tasks.add_task(TaxAgent.stream(input_text))\n",
        "\n",
        "    return StreamingResponse(TaxAgent.stream(input_text))\n",
        "\n"
      ],
      "metadata": {
        "id": "3JWzvodw-pae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NGROK_KEY = userdata.get('NGROK_KEY')"
      ],
      "metadata": {
        "id": "-VVgRJFkAijV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $NGROK_KEY"
      ],
      "metadata": {
        "id": "B2EazjjkAmzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "1O_9cAsvArTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "uvicorn.run(host=\"127.0.0.1\", port=8000, app=app)"
      ],
      "metadata": {
        "id": "Pb1pcpEOAu_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = TaxAgent.invoke({\"input\": \"Compare No of returns,\tNo of single returns,\tNo of joint returns and\tNo of head of household returns for States CA and AL in all the income range?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "hAky1zUCD2zL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}